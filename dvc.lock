schema: '2.0'
stages:
  preprocess:
    cmd: python -u source/preprocess.py
    deps:
    - path: data/raw/
      hash: md5
      md5: 25e54827bb56e0446b074ca8411aec84.dir
      size: 39391890330
      nfiles: 305982
    - path: source/preprocess.py
      hash: md5
      md5: 384ea4345776f9d6e3e5371e6eec5dea
      size: 17607
    params:
      params.yaml:
        preprocess:
          batch_size: 8
          db_writemap: false
          ext:
          - wav
          initial_db_size: 1
          input_path_test: data/raw/nsynth-test
          input_path_train: data/raw/nsynth-train
          input_path_valid: data/raw/nsynth-valid
          model_name: facebook/encodec_24khz
          num_workers: 30
          output_path_test: data/processed/test
          output_path_train: data/processed/train
          output_path_valid: data/processed/valid
          sample_rate: 24000
    outs:
    - path: data/processed/
      hash: md5
      md5: 6e310ab2456715138e33193d0554577d.dir
      size: 130354565120
      nfiles: 6
  train_vae:
    cmd: python -u source/train_vae.py
    deps:
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_vae.py
      hash: md5
      md5: af5e38456e23d2a7d1a7e6cf308e80d2
      size: 25524
    - path: source/vae.py
      hash: md5
      md5: 4aaa5b639db6c02a00d818541d2261fd
      size: 13634
    params:
      params.yaml:
        train:
          vae:
            epochs: 10000
            batch_size: 256
            lr: 0.0003
            wd: 0.05
            betas:
            - 0.9
            - 0.95
            dropout_ratio: 0.1
            eval_interval: 50
            visualize_interval: 50
            hear_interval: 300
            save_interval: 1000
            input_crop: 150
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 1024
            - 512
            linears:
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            rec_beta: 0.8
            neighbor_beta: 1.0
            spa_beta: 0.1
            kl_beta: 0.0039
            note_cls_beta: 0.12
            family_cls_beta: 0.07
            instrument_cls_beta: 0.007
            reg_scaling_exp_neighbor: 0.5
            reg_scaling_exp_family: 1.5
            reg_scaling_exp_instrument: 0.8
            calculate_vae_loss:
              _target_: vae.calculate_vae_loss
              _partial_: true
              num_epochs: 10000
              weighted_reproduction: false
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              batch_size: 256
          transformer:
            epochs: 5000
            batch_size: 96
            learning_rate: 0.0001
            weight_decay: 0.05
            betas:
            - 0.9
            - 0.95
            eval_interval: 50
            visualize_interval: 50
            hear_interval: 500
            save_interval: 1000
            num_batches_evaluation: 20
            block_size: 300
            input_dimension: 128
            internal_dimension: 512
            feedforward_dimension: 4096
            n_layer_encoder: 8
            n_layer_decoder: 12
            n_head: 8
            dropout: 0.1
            condition_model_path: out/vae/checkpoints/vae_final_epoch_10000.torch
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          db_path_test: data/processed/test
          random_seed: 42
          num_workers: 0
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          max_inst_per_family: 10
          velocity:
          - 100
          device: auto
          deterministic: true
          vae_path: out/vae/checkpoints/vae_final_epoch_10000.torch
          transformer_path: out/transformer/checkpoints/transformer_final_epoch_5000.torch
    outs:
    - path: out/vae/
      hash: md5
      md5: e2c5f9ae448b816850e75126f395b2c3.dir
      size: 2921889687
      nfiles: 25
  train_transformer:
    cmd: python -u source/train_transformer.py
    deps:
    - path: out/vae/
      hash: md5
      md5: 4f60139fcef1c9e9b9966bd26dc08770.dir
      size: 7267088948
      nfiles: 18
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_transformer.py
      hash: md5
      md5: 332c746063cb4f1b750cdcab9157976e
      size: 14032
    - path: source/transformer.py
      hash: md5
      md5: b0ab6c83cfee6545cb916446d74e6596
      size: 3834
    params:
      params.yaml:
        train:
          vae:
            epochs: 3000
            batch_size: 256
            lr: 0.0001
            wd: 0.05
            betas:
            - 0.9
            - 0.95
            dropout_ratio: 0.2
            eval_interval: 50
            visualize_interval: 300
            hear_interval: 300
            save_interval: 1000
            input_crop: 150
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 2048
            linears:
            - 8192
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            rec_beta: 0.2
            rep_beta: 0.6
            spa_beta: 1.0
            cla_beta: 0.12
            inst_beta: 0.07
            reg_scaling_exp: 2.0
            calculate_vae_loss:
              _target_: vae.calculate_vae_loss
              _partial_: true
              num_epochs: 3000
              weighted_reproduction: false
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              batch_size: 256
          transformer:
            epochs: 5000
            batch_size: 64
            learning_rate: 0.0001
            weight_decay: 0.05
            betas:
            - 0.9
            - 0.95
            eval_interval: 100
            visualize_interval: 500
            hear_interval: 500
            save_interval: 1000
            num_batches_evaluation: 5
            block_size: 300
            input_dimension: 128
            internal_dimension: 512
            feedforward_dimension: 4096
            n_layer_encoder: 8
            n_layer_decoder: 12
            n_head: 8
            dropout: 0.1
            condition_model_path: out/vae/checkpoints/vae_final_epoch_3000.torch
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          db_path_test: data/processed/test
          random_seed: 42
          num_workers: 30
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          max_inst_per_family: 5
          velocity:
          - 100
          device: auto
          deterministic: true
          vae_path: out/vae/checkpoints/vae_final_epoch_3000.torch
          transformer_path: out/transformer/checkpoints/transformer_final_epoch_5000.torch
    outs:
    - path: out/transformer/
      hash: md5
      md5: 090050d604aaf2d5c049354d68982c36.dir
      size: 2834402543
      nfiles: 12
