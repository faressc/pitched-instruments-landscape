schema: '2.0'
stages:
  preprocess:
    cmd: python -u source/preprocess.py
    deps:
    - path: data/raw/
      hash: md5
      md5: 25e54827bb56e0446b074ca8411aec84.dir
      size: 39391890330
      nfiles: 305982
    - path: source/preprocess.py
      hash: md5
      md5: 384ea4345776f9d6e3e5371e6eec5dea
      size: 17607
    params:
      params.yaml:
        preprocess:
          batch_size: 8
          db_writemap: false
          ext:
          - wav
          initial_db_size: 1
          input_path_test: data/raw/nsynth-test
          input_path_train: data/raw/nsynth-train
          input_path_valid: data/raw/nsynth-valid
          model_name: facebook/encodec_24khz
          num_workers: 30
          output_path_test: data/processed/test
          output_path_train: data/processed/train
          output_path_valid: data/processed/valid
          sample_rate: 24000
    outs:
    - path: data/processed/
      hash: md5
      md5: 6e310ab2456715138e33193d0554577d.dir
      size: 130354565120
      nfiles: 6
  train_vae:
    cmd: python -u source/train_vae.py
    deps:
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_vae.py
      hash: md5
      md5: bd67172d25ec05b6b5ec8ae2230b5a78
      size: 16922
    - path: source/vae.py
      hash: md5
      md5: 97aa4b97177ae845848566963653f8e9
      size: 11760
    params:
      params.yaml:
        train:
          db_path_test: data/processed/test
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          deterministic: true
          device: auto
          max_inst_per_family: 40
          num_workers: 0
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          random_seed: 42
          transformer:
            batch_size: 96
            betas:
            - 0.9
            - 0.95
            block_size: 300
            condition_model_path: out/vae/checkpoints/vae_final_epoch_10000.torch
            dropout: 0.1
            epochs: 5000
            eval_interval: 50
            feedforward_dimension: 4096
            hear_interval: 500
            input_dimension: 128
            internal_dimension: 512
            learning_rate: 0.0001
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
            n_head: 8
            n_layer_decoder: 12
            n_layer_encoder: 8
            num_batches_evaluation: 20
            save_interval: 1000
            visualize_interval: 50
            weight_decay: 0.05
          transformer_path: out/transformer/checkpoints/transformer_final_epoch_5000.torch
          vae:
            batch_size: 256
            betas:
            - 0.9
            - 0.95
            calculate_vae_loss:
              _partial_: true
              _target_: vae.calculate_vae_loss
              batch_size: 256
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              num_epochs: 10000
              weighted_reproduction: false
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 1024
            - 512
            cla_beta: 0.12
            dropout_ratio: 0.1
            epochs: 10000
            eval_interval: 50
            hear_interval: 300
            input_crop: 150
            inst_beta: 0.07
            linears:
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            lr: 0.0003
            rec_beta: 0.8
            reg_scaling_exp: 1.5
            rep_beta: 0.8
            save_interval: 1000
            spa_beta: 0.1
            visualize_interval: 50
            wd: 0.05
          vae_path: out/vae/checkpoints/vae_final_epoch_10000.torch
          velocity:
          - 100
    outs:
    - path: out/vae/
      hash: md5
      md5: ad2069b60dea0840428c92a6a2327d30.dir
      size: 2921758248
      nfiles: 25
  train_transformer:
    cmd: python -u source/train_transformer.py
    deps:
    - path: out/vae/
      hash: md5
      md5: ad2069b60dea0840428c92a6a2327d30.dir
      size: 2921758248
      nfiles: 25
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_transformer.py
      hash: md5
      md5: 559bbbf68f1b4818c875adfec7625002
      size: 14084
    - path: source/transformer.py
      hash: md5
      md5: b0ab6c83cfee6545cb916446d74e6596
      size: 3834
    params:
      params.yaml:
        train:
          vae:
            epochs: 10000
            batch_size: 256
            lr: 0.0003
            wd: 0.05
            betas:
            - 0.9
            - 0.95
            dropout_ratio: 0.1
            eval_interval: 50
            visualize_interval: 50
            hear_interval: 300
            save_interval: 1000
            input_crop: 150
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 1024
            - 512
            linears:
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            rec_beta: 0.8
            rep_beta: 0.8
            spa_beta: 0.1
            cla_beta: 0.12
            inst_beta: 0.07
            reg_scaling_exp: 1.5
            calculate_vae_loss:
              _target_: vae.calculate_vae_loss
              _partial_: true
              num_epochs: 10000
              weighted_reproduction: false
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              batch_size: 256
          transformer:
            epochs: 5000
            batch_size: 64
            learning_rate: 0.0001
            weight_decay: 0.05
            betas:
            - 0.9
            - 0.95
            eval_interval: 50
            visualize_interval: 50
            hear_interval: 500
            save_interval: 1000
            num_batches_evaluation: 20
            block_size: 300
            input_dimension: 128
            internal_dimension: 512
            feedforward_dimension: 4096
            n_layer_encoder: 8
            n_layer_decoder: 12
            n_head: 8
            dropout: 0.1
            condition_model_path: out/vae/checkpoints/vae_final_epoch_10000.torch
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          db_path_test: data/processed/test
          random_seed: 42
          num_workers: 0
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          max_inst_per_family: 40
          velocity:
          - 100
          device: auto
          deterministic: true
          vae_path: out/vae/checkpoints/vae_final_epoch_10000.torch
          transformer_path: out/transformer/checkpoints/transformer_final_epoch_5000.torch
    outs:
    - path: out/transformer/
      hash: md5
      md5: d31593230d4361208f9dfb41e55a709e.dir
      size: 2834377347
      nfiles: 12
