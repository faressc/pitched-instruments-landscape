schema: '2.0'
stages:
  preprocess:
    cmd: python -u source/preprocess.py
    deps:
    - path: data/raw/
      hash: md5
      md5: 25e54827bb56e0446b074ca8411aec84.dir
      size: 39391890330
      nfiles: 305982
    - path: source/preprocess.py
      hash: md5
      md5: 384ea4345776f9d6e3e5371e6eec5dea
      size: 17607
    params:
      params.yaml:
        preprocess:
          batch_size: 8
          db_writemap: false
          ext:
          - wav
          initial_db_size: 1
          input_path_test: data/raw/nsynth-test
          input_path_train: data/raw/nsynth-train
          input_path_valid: data/raw/nsynth-valid
          model_name: facebook/encodec_24khz
          num_workers: 30
          output_path_test: data/processed/test
          output_path_train: data/processed/train
          output_path_valid: data/processed/valid
          sample_rate: 24000
    outs:
    - path: data/processed/
      hash: md5
      md5: 6e310ab2456715138e33193d0554577d.dir
      size: 130354565120
      nfiles: 6
  train_vae:
    cmd: python -u source/train_vae.py
    deps:
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_vae.py
      hash: md5
      md5: dec91c073aeeba69a82bf465f1854ef1
      size: 16662
    - path: source/vae.py
      hash: md5
      md5: 7c70c931fe252201aa3e78b2a7ac1a28
      size: 10935
    params:
      params.yaml:
        train:
          vae:
            epochs: 3000
            batch_size: 256
            lr: 0.0001
            wd: 0.05
            betas:
            - 0.9
            - 0.95
            dropout_ratio: 0.2
            eval_interval: 50
            visualize_interval: 300
            hear_interval: 300
            save_interval: 1000
            input_crop: 150
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 2048
            linears:
            - 8192
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            rec_beta: 0.2
            rep_beta: 0.6
            spa_beta: 1.0
            cla_beta: 0.12
            inst_beta: 0.07
            reg_scaling_exp: 2.0
            calculate_vae_loss:
              _target_: vae.calculate_vae_loss
              _partial_: true
              num_epochs: 3000
              weighted_reproduction: false
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              batch_size: 256
          transformer:
            epochs: 5000
            batch_size: 96
            learning_rate: 0.0001
            weight_decay: 0.05
            betas:
            - 0.9
            - 0.95
            eval_interval: 100
            visualize_interval: 500
            hear_interval: 500
            save_interval: 1000
            num_batches_evaluation: 5
            block_size: 300
            input_dimension: 128
            internal_dimension: 512
            feedforward_dimension: 2048
            n_layer_encoder: 8
            n_layer_decoder: 12
            n_head: 8
            dropout: 0.1
            condition_model_path: out/vae/checkpoints/vae_final_epoch_3000.torch
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          db_path_test: data/processed/test
          random_seed: 42
          num_workers: 30
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          max_inst_per_family: 40
          velocity:
          - 100
          device: auto
          deterministic: true
          vae_path: out/vae/checkpoints/vae_final_epoch_3000.torch
          transformer_path: out/transformer/checkpoints/vae_final_epoch_5000.torch
    outs:
    - path: out/vae/
      hash: md5
      md5: 7bb10ed1e292bc52c1a12a4be7c0eb43.dir
      size: 7267095924
      nfiles: 18
  train_transformer:
    cmd: python -u source/train_transformer.py
    deps:
    - path: out/vae/
      hash: md5
      md5: a64a73e19f7132e874512c778f6ddb4f.dir
      size: 1817922487
      nfiles: 15
    - path: source/dataset.py
      hash: md5
      md5: 3348427ec290bcac2ee111bb4732f4d9
      size: 8452
    - path: source/train_transformer.py
      hash: md5
      md5: 2be50ba4df148e1e3b034c0ced768589
      size: 13956
    - path: source/transformer.py
      hash: md5
      md5: 6d3c97a8026f2685f2fd3b064320b7f4
      size: 3835
    params:
      params.yaml:
        train:
          db_path_test: data/processed/test
          db_path_train: data/processed/train
          db_path_valid: data/processed/valid
          deterministic: true
          device: auto
          max_inst_per_family: 20
          num_workers: 0
          pitch:
          - 48
          - 49
          - 50
          - 51
          - 52
          - 53
          - 54
          - 55
          - 56
          - 57
          - 58
          - 59
          - 60
          - 61
          - 62
          - 63
          - 64
          - 65
          - 66
          - 67
          - 68
          - 69
          - 70
          - 71
          - 72
          random_seed: 42
          transformer:
            batch_size: 64
            betas:
            - 0.9
            - 0.95
            block_size: 300
            condition_model_path: out/vae/checkpoints/vae_final_epoch_200.torch
            dropout: 0.0
            epochs: 5000
            eval_interval: 100
            feedforward_dimension: 1024
            hear_interval: 500
            input_dimension: 128
            internal_dimension: 512
            learning_rate: 0.0001
            loss_fn:
              _target_: torch.nn.MSELoss
              reduction: mean
            n_head: 8
            n_layer_decoder: 12
            n_layer_encoder: 8
            num_batches_evaluation: 5
            save_interval: 500
            visualize_interval: 500
            weight_decay: 0.05
          transformer_path: out/transformer/checkpoints/vae_final_epoch_5000.torch
          vae:
            batch_size: 256
            betas:
            - 0.9
            - 0.95
            calculate_vae_loss:
              _partial_: true
              _target_: vae.calculate_vae_loss
              batch_size: 256
              cls_loss_fn:
                _target_: torch.nn.CrossEntropyLoss
              loss_fn:
                _target_: torch.nn.MSELoss
                reduction: sum
              num_epochs: 1000
              weighted_reproduction: false
            channels:
            - 128
            - 256
            - 512
            - 1024
            - 2048
            cla_beta: 0.12
            dropout_ratio: 0.2
            epochs: 1000
            eval_interval: 5
            hear_interval: 40
            input_crop: 150
            inst_beta: 0.07
            linears:
            - 8192
            - 4096
            - 2048
            - 1024
            - 512
            - 2
            lr: 0.0001
            rec_beta: 0.2
            reg_scaling_exp: 2.0
            rep_beta: 0.6
            save_interval: 40
            spa_beta: 1.0
            visualize_interval: 5
            wd: 0.05
          vae_path: out/vae/checkpoints/vae_final_epoch_1000.torch
          velocity:
          - 100
    outs:
    - path: out/transformer/
      hash: md5
      md5: 6f9756f398a17095b51cea5ff9451e4e.dir
      size: 1322525696
      nfiles: 8
